{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Description\n",
        "**L1 regularization,** also known as **L1 norm or Lasso** (in regression problems), combats overfitting by shrinking the parameters towards **0.** This makes some features obsolete."
      ],
      "metadata": {
        "id": "FvH311BLywZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s a form of feature selection, because when we assign a feature with a **0 weight,** we’re *multiplying the feature values by **0 which returns 0,** eradicating the significance of that feature.*\n",
        "\n",
        "If the input features of our model have weights closer to **0,** our **L1** norm would be sparse. A selection of the input features would have weights equal to zero, and the rest would be non-zero."
      ],
      "metadata": {
        "id": "lJnA8xCNzFp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thanks To:**\n",
        "1. [Fighting Overfitting With L1 or L2 Regularization](https://neptune.ai/blog/fighting-overfitting-with-l1-or-l2-regularization)"
      ],
      "metadata": {
        "id": "vWvSpiw5zwGS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVuhjSrymSKc"
      },
      "outputs": [],
      "source": []
    }
  ]
}