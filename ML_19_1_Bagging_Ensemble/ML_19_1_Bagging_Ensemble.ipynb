{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "## 1.1 Definition\n",
        "### Bagging ensemble is bootstrap aggregation\n",
        "* Bagging works by creating samples of the training dataset and fitting a decision tree on each sample.\n",
        "* The differences in the training datasets result in differences in the fit decision trees, and in turn, differences in predictions made by those trees.\n",
        "* The predictions made by the ensemble members are then combined using simple statistics, such as **voting or averaging.**\n",
        "* Key to the method is the manner in which each sample of the dataset is prepared to train ensemble members.\n",
        "* Examples (rows) are drawn from the dataset at random, although with replacement.\n",
        "* Replacement means that if a row is selected, it is returned to the training dataset for potential re-selection in the same training dataset.\n",
        "* This is called a **bootstrap sample,** giving the technique its name.\n",
        "\n",
        "\n",
        "**Bagging** is available in scikit-learn via the **BaggingClassifier** and **BaggingRegressor classes,** which use a decision tree as the base-model by default and you can specify the number of trees to create via the **n estimators** argument."
      ],
      "metadata": {
        "id": "VCj-WI3ztzCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bagging,** which stands for **Bootstrap Aggregating,** is an ensemble learning technique designed to improve the stability and accuracy of machine learning algorithms.\n",
        "\n",
        "It works particularly well with high-variance models like *decision trees.* The primary idea behind bagging is to combine the predictions of multiple models trained on different subsets of the data to *reduce variance and prevent overfitting.*"
      ],
      "metadata": {
        "id": "oS5u7WQZxqVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import libraries"
      ],
      "metadata": {
        "id": "NMkGlPgQqNu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Pm9s8ZdVtLc1"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}